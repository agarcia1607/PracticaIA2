{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d723f03f",
   "metadata": {},
   "source": [
    "# 📄 Descripción del Dataset: Wine Quality\n",
    "\n",
    "## 📌 Fuente\n",
    "[UCI Machine Learning Repository – Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Resumen General\n",
    "\n",
    "| Atributo                  | Valor                            |\n",
    "|--------------------------|----------------------------------|\n",
    "| **Número de instancias** | 6,497 registros totales          |\n",
    "| **Tipos de vino**        | Vino blanco (4,898) y tinto (1,599) |\n",
    "| **Número de atributos**  | 11 características + 1 objetivo  |\n",
    "| **Tipo de atributos**    | Todos numéricos continuos        |\n",
    "| **Variable objetivo**    | `quality` (entero de 3 a 9)      |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧬 Variables (entradas)\n",
    "\n",
    "Las variables representan propiedades físico-químicas del vino:\n",
    "\n",
    "- `fixed acidity`: Ácido tartárico\n",
    "- `volatile acidity`: Ácido acético\n",
    "- `citric acid`: Ácido cítrico\n",
    "- `residual sugar`: Azúcar residual (g/L)\n",
    "- `chlorides`: Concentración de sal\n",
    "- `free sulfur dioxide`: SO₂ libre\n",
    "- `total sulfur dioxide`: SO₂ total\n",
    "- `density`: Densidad del vino\n",
    "- `pH`: Nivel de acidez\n",
    "- `sulphates`: Sulfatos (agentes conservantes)\n",
    "- `alcohol`: Porcentaje de alcohol (% vol.)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Variable Objetivo: `quality`\n",
    "\n",
    "- Representa la calidad sensorial del vino evaluada por catadores expertos.\n",
    "- Es un entero entre **3 y 9** (7 clases posibles).\n",
    "- Distribución **desbalanceada** (la mayoría son calidad 5 o 6).\n",
    "\n",
    "| Clase (`quality`) | Interpretación        |\n",
    "|-------------------|------------------------|\n",
    "| 3–4               | Calidad muy baja       |\n",
    "| 5–6               | Calidad media          |\n",
    "| 7–9               | Calidad buena a alta   |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Clasificación vs Regresión\n",
    "\n",
    "- Aunque la variable `quality` es numérica discreta, se puede usar como:\n",
    "  - **Clasificación multiclase**: ✅ Recomendado para esta práctica.\n",
    "  - **Regresión**: posible, pero **no se ajusta al objetivo de la práctica**.\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Aplicabilidad en Preprocesamiento\n",
    "\n",
    "| Técnica                      | ¿Aplica?  | Comentario                                     |\n",
    "|-----------------------------|-----------|------------------------------------------------|\n",
    "| Escalado / Normalización    | ✅        | Todas las variables son numéricas              |\n",
    "| Detección de Outliers       | ✅        | Algunas variables tienen valores extremos      |\n",
    "| Balanceo de Clases          | ✅        | Distribución de clases desbalanceada           |\n",
    "| One-hot Encoding             | ⚠️        | No tiene categóricas directas, pero se pueden crear artificialmente |\n",
    "| Clasificación Multiclase    | ✅        | 7 clases disponibles (cumple con los requisitos del trabajo) |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Conclusión\n",
    "\n",
    "El dataset **Wine Quality** es una excelente opción para abordar un problema de **clasificación multiclase supervisado**, permitiendo aplicar técnicas como normalización, detección de outliers, y balanceo de clases. Su estructura simple y bien documentada lo hace ideal para proyectos de aprendizaje de máquinas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da128059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.1-cp311-cp311-win_amd64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.1 MB 1.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/8.1 MB 1.2 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.3/8.1 MB 1.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.6/8.1 MB 1.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.8/8.1 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 1.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.6/8.1 MB 1.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.9/8.1 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.1/8.1 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.4/8.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.4/8.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.7/8.1 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 3.9/8.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.9/8.1 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.2/8.1 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.2/8.1 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.5/8.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 4.5/8.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 4.5/8.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 5.0/8.1 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.2/8.1 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.5/8.1 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.5/8.1 MB 1.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.8/8.1 MB 1.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.8/8.1 MB 1.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.8/8.1 MB 1.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 948.9 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 6.3/8.1 MB 941.2 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.3/8.1 MB 941.2 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.6/8.1 MB 913.1 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.6/8.1 MB 913.1 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.8/8.1 MB 890.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.8/8.1 MB 890.6 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 7.1/8.1 MB 886.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 7.3/8.1 MB 881.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 881.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.6/8.1 MB 879.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 871.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/8.1 MB 871.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 864.1 kB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl (222 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.1-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.2 MB 884.1 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.2 MB 884.1 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.2 MB 762.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.2 MB 762.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.2 MB 762.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.2 MB 762.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.2 MB 762.8 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.0/2.2 MB 762.8 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 462.9 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 462.9 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 471.3 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 471.3 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.8/2.2 MB 491.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 491.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 524.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 528.8 kB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------- ----------------- 4/7 [cycler]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.1 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\agarc\\onedrive\\escritorio\\practicaia2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install torch numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa4d0c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset local...\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Nombre del archivo local\n",
    "archivo_local = \"winequality-white.csv\"\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "\n",
    "# Solo descarga si no existe localmente\n",
    "if not os.path.exists(archivo_local):\n",
    "    print(\"Descargando dataset...\")\n",
    "    df = pd.read_csv(url, sep=';')\n",
    "    df.to_csv(archivo_local, index=False)\n",
    "else:\n",
    "    print(\"Cargando dataset local...\")\n",
    "    df = pd.read_csv(archivo_local)\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b066ea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Intenta cargar el archivo con separador coma\n",
    "df = pd.read_csv(\"winequality-white.csv\", sep=',')\n",
    "\n",
    "# Limpiar espacios en nombres de columnas\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Mostrar nombres de columnas corregidos\n",
    "print(df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846c06a",
   "metadata": {},
   "source": [
    "Creemos el primer dataframe el cual solo tiene la conversión de la variable categorica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8adfcc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  alcohol_level_medio  alcohol_level_alto  \\\n",
      "0      8.8        6                False               False   \n",
      "1      9.5        6                 True               False   \n",
      "2     10.1        6                 True               False   \n",
      "3      9.9        6                 True               False   \n",
      "4      9.9        6                 True               False   \n",
      "\n",
      "   alcohol_level_muy_alto  \n",
      "0                   False  \n",
      "1                   False  \n",
      "2                   False  \n",
      "3                   False  \n",
      "4                   False  \n",
      "Forma: (4898, 15)\n"
     ]
    }
   ],
   "source": [
    "# Crear variable categórica basada en niveles de alcohol\n",
    "df[\"alcohol_level\"] = pd.cut(df[\"alcohol\"],\n",
    "                             bins=[0, 9, 11, 13, 100],\n",
    "                             labels=[\"bajo\", \"medio\", \"alto\", \"muy_alto\"])\n",
    "\n",
    "# Aplicar One-Hot Encoding a 'alcohol_level' (sin escalado aún)\n",
    "df_v1 = pd.get_dummies(df, columns=[\"alcohol_level\"], drop_first=True)\n",
    "\n",
    "# Verificar que se creó correctamente\n",
    "print(df_v1.head())\n",
    "print(\"Forma:\", df_v1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88b9aa",
   "metadata": {},
   "source": [
    "Construyamos el v2, el cual contiene el balanceoy la conversion de las categoricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e2457ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "5    2198\n",
      "4    2198\n",
      "3    2198\n",
      "9    2198\n",
      "8    2198\n",
      "6    2198\n",
      "7    2198\n",
      "Name: count, dtype: int64\n",
      "Forma: (15386, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separar clases\n",
    "df_grupos = [df_v1[df_v1[\"quality\"] == clase] for clase in df_v1[\"quality\"].unique()]\n",
    "\n",
    "# Encontrar la clase más grande\n",
    "max_len = max(len(grupo) for grupo in df_grupos)\n",
    "\n",
    "# Balancear todas las clases al tamaño de la más grande\n",
    "df_resampled = [resample(grupo, \n",
    "                         replace=True, \n",
    "                         n_samples=max_len, \n",
    "                         random_state=42) for grupo in df_grupos]\n",
    "\n",
    "# Combinar y mezclar\n",
    "df_v2 = pd.concat(df_resampled).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verificación\n",
    "print(df_v2[\"quality\"].value_counts())\n",
    "print(\"Forma:\", df_v2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30756a",
   "metadata": {},
   "source": [
    "Sigamos ahora con V3, el cual esta con la conversion de categoricas y el tratamiento de outliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "35d046dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros originales: 4898\n",
      "Registros después de eliminar outliers: 3368\n",
      "Clases: quality\n",
      "6    1577\n",
      "5     928\n",
      "7     651\n",
      "8     122\n",
      "4      79\n",
      "3       7\n",
      "9       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Crear copia base desde df_v1 (ya tiene categóricas codificadas)\n",
    "df_temp = df_v1.copy()\n",
    "\n",
    "# Seleccionamos solo las columnas numéricas originales (sin dummies ni 'quality')\n",
    "columnas_numericas = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "                      'chlorides', 'free sulfur dioxide', 'total sulfur dioxide',\n",
    "                      'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "# Calcular Z-scores\n",
    "z_scores = np.abs(zscore(df_temp[columnas_numericas]))\n",
    "\n",
    "# Eliminar filas con algún Z-score > 2.0 (puedes usar 3.0 si quieres conservar más)\n",
    "umbral = 2.0\n",
    "filtro = (z_scores < umbral).all(axis=1)\n",
    "df_v3 = df_temp[filtro].reset_index(drop=True)\n",
    "\n",
    "# Verificación\n",
    "print(\"Registros originales:\", df_v1.shape[0])\n",
    "print(\"Registros después de eliminar outliers:\", df_v3.shape[0])\n",
    "print(\"Clases:\", df_v3['quality'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8284120",
   "metadata": {},
   "source": [
    "Sigamos ahora con V4, el cual esta con la conversion de categoricas, el tratamiento de outliders y balnaceo de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aa1c829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "6    1577\n",
      "7    1577\n",
      "5    1577\n",
      "3    1577\n",
      "4    1577\n",
      "8    1577\n",
      "9    1577\n",
      "Name: count, dtype: int64\n",
      "Forma: (11039, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Base: df_v3 (ya sin outliers)\n",
    "df_grupos = [df_v3[df_v3[\"quality\"] == clase] for clase in df_v3[\"quality\"].unique()]\n",
    "\n",
    "# Tamaño de la clase más grande\n",
    "max_len = max(len(grupo) for grupo in df_grupos)\n",
    "\n",
    "# Sobremuestreo de todas las clases\n",
    "df_resampled = [\n",
    "    resample(grupo, replace=True, n_samples=max_len, random_state=42)\n",
    "    for grupo in df_grupos\n",
    "]\n",
    "\n",
    "# Unir y mezclar\n",
    "df_v4 = pd.concat(df_resampled).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verificación\n",
    "print(df_v4[\"quality\"].value_counts())\n",
    "print(\"Forma:\", df_v4.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f5aea",
   "metadata": {},
   "source": [
    "Construyamos ahora v5 con la conversion categorica + escalado de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2b5c59f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0       0.307692          0.186275     0.216867        0.308282   0.106825   \n",
      "1       0.240385          0.215686     0.204819        0.015337   0.118694   \n",
      "2       0.413462          0.196078     0.240964        0.096626   0.121662   \n",
      "3       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
      "4       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
      "0             0.149826              0.373550  0.267785  0.254545   0.267442   \n",
      "1             0.041812              0.285383  0.132832  0.527273   0.313953   \n",
      "2             0.097561              0.204176  0.154039  0.490909   0.255814   \n",
      "3             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
      "4             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
      "\n",
      "    alcohol  quality  alcohol_level_medio  alcohol_level_alto  \\\n",
      "0  0.129032        6                False               False   \n",
      "1  0.241935        6                 True               False   \n",
      "2  0.338710        6                 True               False   \n",
      "3  0.306452        6                 True               False   \n",
      "4  0.306452        6                 True               False   \n",
      "\n",
      "   alcohol_level_muy_alto  \n",
      "0                   False  \n",
      "1                   False  \n",
      "2                   False  \n",
      "3                   False  \n",
      "4                   False  \n",
      "Forma: (4898, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Base: df_v1\n",
    "df_v5 = df_v1.copy()\n",
    "\n",
    "# Columnas numéricas originales (sin 'quality' ni dummies)\n",
    "columnas_numericas = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "                      'chlorides', 'free sulfur dioxide', 'total sulfur dioxide',\n",
    "                      'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "# Aplicar escalado Min-Max\n",
    "scaler = MinMaxScaler()\n",
    "df_v5[columnas_numericas] = scaler.fit_transform(df_v5[columnas_numericas])\n",
    "\n",
    "# Verificar\n",
    "print(df_v5.head())\n",
    "print(\"Forma:\", df_v5.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2532d7",
   "metadata": {},
   "source": [
    "Creemos ahora el v6 categóricas convertidas + escalado + balanceo de clases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "157acd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "5    2198\n",
      "4    2198\n",
      "3    2198\n",
      "9    2198\n",
      "8    2198\n",
      "6    2198\n",
      "7    2198\n",
      "Name: count, dtype: int64\n",
      "Forma: (15386, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Base: df_v5\n",
    "df_grupos = [df_v5[df_v5[\"quality\"] == clase] for clase in df_v5[\"quality\"].unique()]\n",
    "\n",
    "# Encontrar clase con más registros\n",
    "max_len = max(len(grupo) for grupo in df_grupos)\n",
    "\n",
    "# Sobremuestreo para balancear\n",
    "df_resampled = [\n",
    "    resample(grupo, replace=True, n_samples=max_len, random_state=42)\n",
    "    for grupo in df_grupos\n",
    "]\n",
    "\n",
    "# Combinar y mezclar\n",
    "df_v6 = pd.concat(df_resampled).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verificación\n",
    "print(df_v6[\"quality\"].value_counts())\n",
    "print(\"Forma:\", df_v6.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472dfed",
   "metadata": {},
   "source": [
    "Construyamos v7, Conversión categórica + Escalado + Eliminación de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7a7df293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros originales: 4898\n",
      "Registros después de eliminar outliers: 3368\n",
      "Distribución de clases:\n",
      " quality\n",
      "6    1577\n",
      "5     928\n",
      "7     651\n",
      "8     122\n",
      "4      79\n",
      "3       7\n",
      "9       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Base: df_v5\n",
    "df_temp = df_v5.copy()\n",
    "\n",
    "# Columnas numéricas escaladas\n",
    "columnas_numericas = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "                      'chlorides', 'free sulfur dioxide', 'total sulfur dioxide',\n",
    "                      'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "# Calcular z-score y filtrar\n",
    "z_scores = np.abs(zscore(df_temp[columnas_numericas]))\n",
    "umbral = 2.0\n",
    "filtro = (z_scores < umbral).all(axis=1)\n",
    "\n",
    "# Aplicar filtro\n",
    "df_v7 = df_temp[filtro].reset_index(drop=True)\n",
    "\n",
    "# Verificación\n",
    "print(\"Registros originales:\", df_v5.shape[0])\n",
    "print(\"Registros después de eliminar outliers:\", df_v7.shape[0])\n",
    "print(\"Distribución de clases:\\n\", df_v7[\"quality\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c99e1f",
   "metadata": {},
   "source": [
    "Hagamos ahora v8 Conversión categórica + Escalado + Outliers + Balanceo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "01cc69ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality\n",
      "6    1577\n",
      "7    1577\n",
      "5    1577\n",
      "3    1577\n",
      "4    1577\n",
      "8    1577\n",
      "9    1577\n",
      "Name: count, dtype: int64\n",
      "Forma final: (11039, 15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Base: df_v7\n",
    "df_grupos = [df_v7[df_v7[\"quality\"] == clase] for clase in df_v7[\"quality\"].unique()]\n",
    "\n",
    "# Encontrar la clase más numerosa\n",
    "max_len = max(len(grupo) for grupo in df_grupos)\n",
    "\n",
    "# Sobremuestreo\n",
    "df_resampled = [\n",
    "    resample(grupo, replace=True, n_samples=max_len, random_state=42)\n",
    "    for grupo in df_grupos\n",
    "]\n",
    "\n",
    "# Combinar y mezclar\n",
    "df_v8 = pd.concat(df_resampled).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Verificación\n",
    "print(df_v8[\"quality\"].value_counts())\n",
    "print(\"Forma final:\", df_v8.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3cb8a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_v1.csv guardado.\n",
      "df_v2.csv guardado.\n",
      "df_v3.csv guardado.\n",
      "df_v4.csv guardado.\n",
      "df_v5.csv guardado.\n",
      "df_v6.csv guardado.\n",
      "df_v7.csv guardado.\n",
      "df_v8.csv guardado.\n"
     ]
    }
   ],
   "source": [
    "# Lista de versiones y nombres\n",
    "versiones = {\n",
    "    \"df_v1\": df_v1,\n",
    "    \"df_v2\": df_v2,\n",
    "    \"df_v3\": df_v3,\n",
    "    \"df_v4\": df_v4,\n",
    "    \"df_v5\": df_v5,\n",
    "    \"df_v6\": df_v6,\n",
    "    \"df_v7\": df_v7,\n",
    "    \"df_v8\": df_v8\n",
    "}\n",
    "\n",
    "# Guardar cada versión como CSV\n",
    "for nombre, df in versiones.items():\n",
    "    df.to_csv(f\"{nombre}.csv\", index=False)\n",
    "    print(f\"{nombre}.csv guardado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc54f92e",
   "metadata": {},
   "source": [
    "Generacion de los split y evaluacion de modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d1d560fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluando df_v1.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.28      0.22      0.25        49\n",
      "           2       0.61      0.61      0.61       437\n",
      "           3       0.63      0.62      0.63       660\n",
      "           4       0.52      0.58      0.55       264\n",
      "           5       0.47      0.51      0.49        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.32      0.18      0.23        49\n",
      "           2       0.55      0.59      0.57       437\n",
      "           3       0.58      0.64      0.61       660\n",
      "           4       0.52      0.46      0.49       264\n",
      "           5       0.40      0.11      0.18        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.34      0.28      0.30      1470\n",
      "weighted avg       0.54      0.55      0.54      1470\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00        49\n",
      "           2       0.61      0.60      0.60       437\n",
      "           3       0.55      0.76      0.64       660\n",
      "           4       0.54      0.25      0.35       264\n",
      "           5       0.00      0.00      0.00        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.24      0.23      0.23      1470\n",
      "weighted avg       0.52      0.57      0.53      1470\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00        49\n",
      "           2       0.70      0.08      0.15       437\n",
      "           3       0.46      0.96      0.62       660\n",
      "           4       0.53      0.07      0.12       264\n",
      "           5       0.00      0.00      0.00        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.47      1470\n",
      "   macro avg       0.24      0.16      0.13      1470\n",
      "weighted avg       0.51      0.47      0.35      1470\n",
      "\n",
      "\n",
      "📊 Evaluando df_v2.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       659\n",
      "           1       0.96      1.00      0.98       659\n",
      "           2       0.88      0.88      0.88       659\n",
      "           3       0.85      0.75      0.80       660\n",
      "           4       0.88      0.90      0.89       660\n",
      "           5       0.95      1.00      0.97       659\n",
      "           6       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           0.93      4616\n",
      "   macro avg       0.93      0.93      0.93      4616\n",
      "weighted avg       0.93      0.93      0.93      4616\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       659\n",
      "           1       0.87      0.99      0.93       659\n",
      "           2       0.73      0.72      0.73       659\n",
      "           3       0.64      0.46      0.54       660\n",
      "           4       0.75      0.78      0.76       660\n",
      "           5       0.88      0.99      0.94       659\n",
      "           6       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           0.85      4616\n",
      "   macro avg       0.84      0.85      0.84      4616\n",
      "weighted avg       0.84      0.85      0.84      4616\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       659\n",
      "           1       0.76      0.86      0.81       659\n",
      "           2       0.62      0.59      0.60       659\n",
      "           3       0.46      0.36      0.40       660\n",
      "           4       0.59      0.56      0.58       660\n",
      "           5       0.74      0.84      0.78       659\n",
      "           6       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           0.74      4616\n",
      "   macro avg       0.73      0.74      0.74      4616\n",
      "weighted avg       0.73      0.74      0.74      4616\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.47       659\n",
      "           1       0.45      0.33      0.38       659\n",
      "           2       0.33      0.67      0.44       659\n",
      "           3       0.21      0.04      0.07       660\n",
      "           4       0.44      0.08      0.13       660\n",
      "           5       0.37      0.34      0.35       659\n",
      "           6       0.43      0.76      0.55       660\n",
      "\n",
      "    accuracy                           0.39      4616\n",
      "   macro avg       0.38      0.39      0.34      4616\n",
      "weighted avg       0.38      0.39      0.34      4616\n",
      "\n",
      "\n",
      "📊 Evaluando df_v3.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.29      0.29      0.29        24\n",
      "           2       0.63      0.62      0.62       279\n",
      "           3       0.64      0.64      0.64       473\n",
      "           4       0.51      0.55      0.53       195\n",
      "           5       0.46      0.32      0.38        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60      1011\n",
      "   macro avg       0.36      0.35      0.35      1011\n",
      "weighted avg       0.60      0.60      0.59      1011\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.58      0.62      0.60       279\n",
      "           3       0.61      0.71      0.65       473\n",
      "           4       0.51      0.37      0.43       195\n",
      "           5       0.33      0.14      0.19        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.58      1011\n",
      "   macro avg       0.29      0.26      0.27      1011\n",
      "weighted avg       0.55      0.58      0.56      1011\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.64      0.60      0.62       279\n",
      "           3       0.56      0.82      0.67       473\n",
      "           4       0.63      0.21      0.32       195\n",
      "           5       0.00      0.00      0.00        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59      1011\n",
      "   macro avg       0.26      0.23      0.23      1011\n",
      "weighted avg       0.56      0.59      0.54      1011\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.55      0.37      0.44       279\n",
      "           3       0.49      0.85      0.62       473\n",
      "           4       0.00      0.00      0.00       195\n",
      "           5       0.00      0.00      0.00        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      1011\n",
      "   macro avg       0.15      0.17      0.15      1011\n",
      "weighted avg       0.38      0.50      0.41      1011\n",
      "\n",
      "\n",
      "📊 Evaluando df_v4.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       473\n",
      "           1       0.96      1.00      0.98       473\n",
      "           2       0.90      0.90      0.90       473\n",
      "           3       0.88      0.78      0.83       473\n",
      "           4       0.89      0.93      0.91       473\n",
      "           5       0.98      1.00      0.99       473\n",
      "           6       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           0.94      3312\n",
      "   macro avg       0.94      0.94      0.94      3312\n",
      "weighted avg       0.94      0.94      0.94      3312\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       473\n",
      "           1       0.86      1.00      0.93       473\n",
      "           2       0.76      0.74      0.75       473\n",
      "           3       0.68      0.54      0.60       473\n",
      "           4       0.78      0.73      0.75       473\n",
      "           5       0.89      1.00      0.94       473\n",
      "           6       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           0.86      3312\n",
      "   macro avg       0.85      0.86      0.85      3312\n",
      "weighted avg       0.85      0.86      0.85      3312\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       473\n",
      "           1       0.83      0.97      0.89       473\n",
      "           2       0.74      0.64      0.69       473\n",
      "           3       0.60      0.46      0.52       473\n",
      "           4       0.64      0.68      0.66       473\n",
      "           5       0.79      0.89      0.83       473\n",
      "           6       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           0.81      3312\n",
      "   macro avg       0.80      0.81      0.80      3312\n",
      "weighted avg       0.80      0.81      0.80      3312\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.29      0.36       473\n",
      "           1       0.38      0.53      0.44       473\n",
      "           2       0.31      0.42      0.35       473\n",
      "           3       0.30      0.12      0.17       473\n",
      "           4       0.30      0.17      0.22       473\n",
      "           5       0.31      0.23      0.26       473\n",
      "           6       0.52      1.00      0.69       474\n",
      "\n",
      "    accuracy                           0.39      3312\n",
      "   macro avg       0.37      0.39      0.36      3312\n",
      "weighted avg       0.37      0.39      0.36      3312\n",
      "\n",
      "\n",
      "📊 Evaluando df_v5.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.28      0.22      0.25        49\n",
      "           2       0.61      0.61      0.61       437\n",
      "           3       0.63      0.62      0.63       660\n",
      "           4       0.52      0.58      0.55       264\n",
      "           5       0.47      0.51      0.49        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59      1470\n",
      "   macro avg       0.36      0.36      0.36      1470\n",
      "weighted avg       0.59      0.59      0.59      1470\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.32      0.18      0.23        49\n",
      "           2       0.55      0.59      0.57       437\n",
      "           3       0.58      0.64      0.61       660\n",
      "           4       0.52      0.46      0.49       264\n",
      "           5       0.40      0.11      0.18        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.55      1470\n",
      "   macro avg       0.34      0.28      0.30      1470\n",
      "weighted avg       0.54      0.55      0.54      1470\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00        49\n",
      "           2       0.61      0.60      0.60       437\n",
      "           3       0.55      0.76      0.64       660\n",
      "           4       0.54      0.25      0.35       264\n",
      "           5       0.00      0.00      0.00        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57      1470\n",
      "   macro avg       0.24      0.23      0.23      1470\n",
      "weighted avg       0.52      0.57      0.53      1470\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00        49\n",
      "           2       0.56      0.50      0.53       437\n",
      "           3       0.49      0.79      0.60       660\n",
      "           4       0.50      0.02      0.03       264\n",
      "           5       0.00      0.00      0.00        53\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51      1470\n",
      "   macro avg       0.22      0.19      0.17      1470\n",
      "weighted avg       0.47      0.51      0.43      1470\n",
      "\n",
      "\n",
      "📊 Evaluando df_v6.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       659\n",
      "           1       0.96      1.00      0.98       659\n",
      "           2       0.88      0.88      0.88       659\n",
      "           3       0.85      0.75      0.80       660\n",
      "           4       0.88      0.90      0.89       660\n",
      "           5       0.95      1.00      0.97       659\n",
      "           6       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           0.93      4616\n",
      "   macro avg       0.93      0.93      0.93      4616\n",
      "weighted avg       0.93      0.93      0.93      4616\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       659\n",
      "           1       0.87      0.99      0.93       659\n",
      "           2       0.73      0.72      0.73       659\n",
      "           3       0.64      0.46      0.54       660\n",
      "           4       0.75      0.78      0.76       660\n",
      "           5       0.88      0.99      0.94       659\n",
      "           6       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           0.85      4616\n",
      "   macro avg       0.84      0.85      0.84      4616\n",
      "weighted avg       0.84      0.85      0.84      4616\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       659\n",
      "           1       0.76      0.86      0.81       659\n",
      "           2       0.62      0.59      0.60       659\n",
      "           3       0.46      0.36      0.40       660\n",
      "           4       0.59      0.56      0.58       660\n",
      "           5       0.74      0.84      0.78       659\n",
      "           6       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           0.74      4616\n",
      "   macro avg       0.73      0.74      0.74      4616\n",
      "weighted avg       0.73      0.74      0.74      4616\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45       659\n",
      "           1       0.38      0.52      0.44       659\n",
      "           2       0.37      0.45      0.40       659\n",
      "           3       0.26      0.08      0.12       660\n",
      "           4       0.20      0.05      0.09       660\n",
      "           5       0.38      0.31      0.34       659\n",
      "           6       0.42      0.76      0.55       660\n",
      "\n",
      "    accuracy                           0.38      4616\n",
      "   macro avg       0.35      0.38      0.34      4616\n",
      "weighted avg       0.35      0.38      0.34      4616\n",
      "\n",
      "\n",
      "📊 Evaluando df_v7.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.29      0.29      0.29        24\n",
      "           2       0.63      0.62      0.62       279\n",
      "           3       0.64      0.64      0.64       473\n",
      "           4       0.51      0.55      0.53       195\n",
      "           5       0.46      0.32      0.38        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60      1011\n",
      "   macro avg       0.36      0.35      0.35      1011\n",
      "weighted avg       0.60      0.60      0.59      1011\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.58      0.62      0.60       279\n",
      "           3       0.61      0.71      0.65       473\n",
      "           4       0.51      0.37      0.43       195\n",
      "           5       0.33      0.14      0.19        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.58      1011\n",
      "   macro avg       0.29      0.26      0.27      1011\n",
      "weighted avg       0.55      0.58      0.56      1011\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.64      0.60      0.62       279\n",
      "           3       0.56      0.82      0.67       473\n",
      "           4       0.63      0.21      0.32       195\n",
      "           5       0.00      0.00      0.00        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59      1011\n",
      "   macro avg       0.26      0.23      0.23      1011\n",
      "weighted avg       0.56      0.59      0.54      1011\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00        24\n",
      "           2       0.79      0.15      0.25       279\n",
      "           3       0.48      0.97      0.65       473\n",
      "           4       0.25      0.01      0.01       195\n",
      "           5       0.00      0.00      0.00        37\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50      1011\n",
      "   macro avg       0.22      0.16      0.13      1011\n",
      "weighted avg       0.49      0.50      0.37      1011\n",
      "\n",
      "\n",
      "📊 Evaluando df_v8.csv\n",
      "\n",
      "🌳 Árbol de Decisión:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       473\n",
      "           1       0.96      1.00      0.98       473\n",
      "           2       0.90      0.90      0.90       473\n",
      "           3       0.88      0.78      0.83       473\n",
      "           4       0.89      0.93      0.91       473\n",
      "           5       0.98      1.00      0.99       473\n",
      "           6       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           0.94      3312\n",
      "   macro avg       0.94      0.94      0.94      3312\n",
      "weighted avg       0.94      0.94      0.94      3312\n",
      "\n",
      "\n",
      "👥 KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       473\n",
      "           1       0.86      1.00      0.93       473\n",
      "           2       0.76      0.74      0.75       473\n",
      "           3       0.68      0.54      0.60       473\n",
      "           4       0.78      0.73      0.75       473\n",
      "           5       0.89      1.00      0.94       473\n",
      "           6       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           0.86      3312\n",
      "   macro avg       0.85      0.86      0.85      3312\n",
      "weighted avg       0.85      0.86      0.85      3312\n",
      "\n",
      "\n",
      "💠 SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       473\n",
      "           1       0.83      0.97      0.89       473\n",
      "           2       0.74      0.64      0.69       473\n",
      "           3       0.60      0.46      0.52       473\n",
      "           4       0.64      0.68      0.66       473\n",
      "           5       0.79      0.89      0.83       473\n",
      "           6       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           0.81      3312\n",
      "   macro avg       0.80      0.81      0.80      3312\n",
      "weighted avg       0.80      0.81      0.80      3312\n",
      "\n",
      "\n",
      "🧠 Red Neuronal (PyTorch):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55       473\n",
      "           1       0.39      0.64      0.48       473\n",
      "           2       0.41      0.27      0.32       473\n",
      "           3       0.25      0.14      0.18       473\n",
      "           4       0.22      0.02      0.04       473\n",
      "           5       0.35      0.32      0.33       473\n",
      "           6       0.50      1.00      0.67       474\n",
      "\n",
      "    accuracy                           0.42      3312\n",
      "   macro avg       0.38      0.42      0.37      3312\n",
      "weighted avg       0.38      0.42      0.37      3312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dataset versions\n",
    "versiones = [f\"df_v{i}.csv\" for i in range(1, 9)]\n",
    "\n",
    "# Red neuronal con regularización\n",
    "class WineNet(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(WineNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "def entrenar_y_evaluar(df, nombre):\n",
    "    print(f\"\\n📊 Evaluando {nombre}\")\n",
    "\n",
    "    # Separar características y etiquetas\n",
    "    X = df.drop(\"quality\", axis=1)\n",
    "    y = df[\"quality\"]\n",
    "\n",
    "    # 🔧 Reindexar las clases para PyTorch\n",
    "    unique_classes = sorted(y.unique())\n",
    "    class_to_index = {c: i for i, c in enumerate(unique_classes)}\n",
    "    y = y.map(class_to_index)\n",
    "    num_classes = len(unique_classes)\n",
    "\n",
    "    # Escalar características\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    # 🌳 Árbol de Decisión\n",
    "    tree = DecisionTreeClassifier(random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_pred_tree = tree.predict(X_test)\n",
    "    print(\"\\n🌳 Árbol de Decisión:\")\n",
    "    print(classification_report(y_test, y_pred_tree, zero_division=0))\n",
    "\n",
    "    # 👥 KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    print(\"\\n👥 KNN:\")\n",
    "    print(classification_report(y_test, y_pred_knn, zero_division=0))\n",
    "\n",
    "    # 💠 SVM\n",
    "    svm = SVC(kernel=\"rbf\", C=1.0)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "    print(\"\\n💠 SVM:\")\n",
    "    print(classification_report(y_test, y_pred_svm, zero_division=0))\n",
    "\n",
    "    # 🧠 Red Neuronal (PyTorch)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "    model = WineNet(input_size=X.shape[1], num_classes=num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train_tensor)\n",
    "        loss = criterion(output, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Early stopping\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        if early_stopping_counter >= 5:\n",
    "            break\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_nn = model(X_test_tensor).argmax(dim=1).numpy()\n",
    "    print(\"\\n🧠 Red Neuronal (PyTorch):\")\n",
    "    print(classification_report(y_test, y_pred_nn, zero_division=0))\n",
    "\n",
    "# Iterar sobre los datasets\n",
    "for archivo in versiones:\n",
    "    df = pd.read_csv(archivo)\n",
    "    entrenar_y_evaluar(df, archivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "08e685a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     dataset      modelo  accuracy  precision  recall  f1-score\n",
      "0  df_v1.csv   Decisión:      0.59       0.36    0.36      0.36\n",
      "1  df_v1.csv  (PyTorch):      0.59       0.36    0.36      0.36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Texto con los resultados\n",
    "texto_resultados = \"\"\"[📊 Evaluando df_v1.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.28      0.22      0.25        49\n",
    "           2       0.61      0.61      0.61       437\n",
    "           3       0.63      0.62      0.63       660\n",
    "           4       0.52      0.58      0.55       264\n",
    "           5       0.47      0.51      0.49        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.59      1470\n",
    "   macro avg       0.36      0.36      0.36      1470\n",
    "weighted avg       0.59      0.59      0.59      1470\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.32      0.18      0.23        49\n",
    "           2       0.55      0.59      0.57       437\n",
    "           3       0.58      0.64      0.61       660\n",
    "           4       0.52      0.46      0.49       264\n",
    "           5       0.40      0.11      0.18        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.55      1470\n",
    "   macro avg       0.34      0.28      0.30      1470\n",
    "weighted avg       0.54      0.55      0.54      1470\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.00      0.00      0.00        49\n",
    "           2       0.61      0.60      0.60       437\n",
    "           3       0.55      0.76      0.64       660\n",
    "           4       0.54      0.25      0.35       264\n",
    "           5       0.00      0.00      0.00        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.57      1470\n",
    "   macro avg       0.24      0.23      0.23      1470\n",
    "weighted avg       0.52      0.57      0.53      1470\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.00      0.00      0.00        49\n",
    "           2       0.70      0.08      0.15       437\n",
    "           3       0.46      0.96      0.62       660\n",
    "           4       0.53      0.07      0.12       264\n",
    "           5       0.00      0.00      0.00        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.47      1470\n",
    "   macro avg       0.24      0.16      0.13      1470\n",
    "weighted avg       0.51      0.47      0.35      1470\n",
    "\n",
    "\n",
    "📊 Evaluando df_v2.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       659\n",
    "           1       0.96      1.00      0.98       659\n",
    "           2       0.88      0.88      0.88       659\n",
    "           3       0.85      0.75      0.80       660\n",
    "           4       0.88      0.90      0.89       660\n",
    "           5       0.95      1.00      0.97       659\n",
    "           6       1.00      1.00      1.00       660\n",
    "\n",
    "    accuracy                           0.93      4616\n",
    "   macro avg       0.93      0.93      0.93      4616\n",
    "weighted avg       0.93      0.93      0.93      4616\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00       659\n",
    "           1       0.87      0.99      0.93       659\n",
    "           2       0.73      0.72      0.73       659\n",
    "           3       0.64      0.46      0.54       660\n",
    "           4       0.75      0.78      0.76       660\n",
    "           5       0.88      0.99      0.94       659\n",
    "           6       1.00      1.00      1.00       660\n",
    "\n",
    "    accuracy                           0.85      4616\n",
    "   macro avg       0.84      0.85      0.84      4616\n",
    "weighted avg       0.84      0.85      0.84      4616\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      1.00      0.99       659\n",
    "           1       0.76      0.86      0.81       659\n",
    "           2       0.62      0.59      0.60       659\n",
    "           3       0.46      0.36      0.40       660\n",
    "           4       0.59      0.56      0.58       660\n",
    "           5       0.74      0.84      0.78       659\n",
    "           6       1.00      1.00      1.00       660\n",
    "\n",
    "    accuracy                           0.74      4616\n",
    "   macro avg       0.73      0.74      0.74      4616\n",
    "weighted avg       0.73      0.74      0.74      4616\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.43      0.50      0.47       659\n",
    "           1       0.45      0.33      0.38       659\n",
    "           2       0.33      0.67      0.44       659\n",
    "           3       0.21      0.04      0.07       660\n",
    "           4       0.44      0.08      0.13       660\n",
    "           5       0.37      0.34      0.35       659\n",
    "           6       0.43      0.76      0.55       660\n",
    "\n",
    "    accuracy                           0.39      4616\n",
    "   macro avg       0.38      0.39      0.34      4616\n",
    "weighted avg       0.38      0.39      0.34      4616\n",
    "\n",
    "\n",
    "📊 Evaluando df_v3.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.29      0.29      0.29        24\n",
    "           2       0.63      0.62      0.62       279\n",
    "           3       0.64      0.64      0.64       473\n",
    "           4       0.51      0.55      0.53       195\n",
    "           5       0.46      0.32      0.38        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.60      1011\n",
    "   macro avg       0.36      0.35      0.35      1011\n",
    "weighted avg       0.60      0.60      0.59      1011\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.00      0.00      0.00        24\n",
    "           2       0.58      0.62      0.60       279\n",
    "           3       0.61      0.71      0.65       473\n",
    "           4       0.51      0.37      0.43       195\n",
    "           5       0.33      0.14      0.19        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.58      1011\n",
    "   macro avg       0.29      0.26      0.27      1011\n",
    "weighted avg       0.55      0.58      0.56      1011\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.00      0.00      0.00        24\n",
    "           2       0.64      0.60      0.62       279\n",
    "           3       0.56      0.82      0.67       473\n",
    "           4       0.63      0.21      0.32       195\n",
    "           5       0.00      0.00      0.00        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.59      1011\n",
    "   macro avg       0.26      0.23      0.23      1011\n",
    "weighted avg       0.56      0.59      0.54      1011\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.00      0.00      0.00        24\n",
    "           2       0.55      0.37      0.44       279\n",
    "           3       0.49      0.85      0.62       473\n",
    "           4       0.00      0.00      0.00       195\n",
    "           5       0.00      0.00      0.00        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.50      1011\n",
    "   macro avg       0.15      0.17      0.15      1011\n",
    "weighted avg       0.38      0.50      0.41      1011\n",
    "\n",
    "\n",
    "📊 Evaluando df_v4.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00       473\n",
    "           1       0.96      1.00      0.98       473\n",
    "           2       0.90      0.90      0.90       473\n",
    "           3       0.88      0.78      0.83       473\n",
    "           4       0.89      0.93      0.91       473\n",
    "           5       0.98      1.00      0.99       473\n",
    "           6       1.00      1.00      1.00       474\n",
    "\n",
    "    accuracy                           0.94      3312\n",
    "   macro avg       0.94      0.94      0.94      3312\n",
    "weighted avg       0.94      0.94      0.94      3312\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00       473\n",
    "           1       0.86      1.00      0.93       473\n",
    "           2       0.76      0.74      0.75       473\n",
    "           3       0.68      0.54      0.60       473\n",
    "           4       0.78      0.73      0.75       473\n",
    "           5       0.89      1.00      0.94       473\n",
    "           6       1.00      1.00      1.00       474\n",
    "\n",
    "    accuracy                           0.86      3312\n",
    "   macro avg       0.85      0.86      0.85      3312\n",
    "weighted avg       0.85      0.86      0.85      3312\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      0.99       473\n",
    "           1       0.83      0.97      0.89       473\n",
    "           2       0.74      0.64      0.69       473\n",
    "           3       0.60      0.46      0.52       473\n",
    "           4       0.64      0.68      0.66       473\n",
    "           5       0.79      0.89      0.83       473\n",
    "           6       1.00      1.00      1.00       474\n",
    "\n",
    "    accuracy                           0.81      3312\n",
    "   macro avg       0.80      0.81      0.80      3312\n",
    "weighted avg       0.80      0.81      0.80      3312\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.46      0.29      0.36       473\n",
    "           1       0.38      0.53      0.44       473\n",
    "           2       0.31      0.42      0.35       473\n",
    "           3       0.30      0.12      0.17       473\n",
    "           4       0.30      0.17      0.22       473\n",
    "           5       0.31      0.23      0.26       473\n",
    "           6       0.52      1.00      0.69       474\n",
    "\n",
    "    accuracy                           0.39      3312\n",
    "   macro avg       0.37      0.39      0.36      3312\n",
    "weighted avg       0.37      0.39      0.36      3312\n",
    "\n",
    "\n",
    "📊 Evaluando df_v5.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.28      0.22      0.25        49\n",
    "           2       0.61      0.61      0.61       437\n",
    "           3       0.63      0.62      0.63       660\n",
    "           4       0.52      0.58      0.55       264\n",
    "           5       0.47      0.51      0.49        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.59      1470\n",
    "   macro avg       0.36      0.36      0.36      1470\n",
    "weighted avg       0.59      0.59      0.59      1470\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.32      0.18      0.23        49\n",
    "           2       0.55      0.59      0.57       437\n",
    "           3       0.58      0.64      0.61       660\n",
    "           4       0.52      0.46      0.49       264\n",
    "           5       0.40      0.11      0.18        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.55      1470\n",
    "   macro avg       0.34      0.28      0.30      1470\n",
    "weighted avg       0.54      0.55      0.54      1470\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.00      0.00      0.00        49\n",
    "           2       0.61      0.60      0.60       437\n",
    "           3       0.55      0.76      0.64       660\n",
    "           4       0.54      0.25      0.35       264\n",
    "           5       0.00      0.00      0.00        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.57      1470\n",
    "   macro avg       0.24      0.23      0.23      1470\n",
    "weighted avg       0.52      0.57      0.53      1470\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         6\n",
    "           1       0.00      0.00      0.00        49\n",
    "           2       0.56      0.50      0.53       437\n",
    "           3       0.49      0.79      0.60       660\n",
    "           4       0.50      0.02      0.03       264\n",
    "           5       0.00      0.00      0.00        53\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.51      1470\n",
    "   macro avg       0.22      0.19      0.17      1470\n",
    "weighted avg       0.47      0.51      0.43      1470\n",
    "\n",
    "\n",
    "📊 Evaluando df_v6.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       659\n",
    "           1       0.96      1.00      0.98       659\n",
    "           2       0.88      0.88      0.88       659\n",
    "           3       0.85      0.75      0.80       660\n",
    "           4       0.88      0.90      0.89       660\n",
    "           5       0.95      1.00      0.97       659\n",
    "           6       1.00      1.00      1.00       660\n",
    "\n",
    "    accuracy                           0.93      4616\n",
    "   macro avg       0.93      0.93      0.93      4616\n",
    "weighted avg       0.93      0.93      0.93      4616\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00       659\n",
    "           1       0.87      0.99      0.93       659\n",
    "           2       0.73      0.72      0.73       659\n",
    "           3       0.64      0.46      0.54       660\n",
    "           4       0.75      0.78      0.76       660\n",
    "           5       0.88      0.99      0.94       659\n",
    "           6       1.00      1.00      1.00       660\n",
    "\n",
    "    accuracy                           0.85      4616\n",
    "   macro avg       0.84      0.85      0.84      4616\n",
    "weighted avg       0.84      0.85      0.84      4616\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      1.00      0.99       659\n",
    "           1       0.76      0.86      0.81       659\n",
    "           2       0.62      0.59      0.60       659\n",
    "           3       0.46      0.36      0.40       660\n",
    "           4       0.59      0.56      0.58       660\n",
    "           5       0.74      0.84      0.78       659\n",
    "           6       1.00      1.00      1.00       660\n",
    "\n",
    "    accuracy                           0.74      4616\n",
    "   macro avg       0.73      0.74      0.74      4616\n",
    "weighted avg       0.73      0.74      0.74      4616\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.41      0.50      0.45       659\n",
    "           1       0.38      0.52      0.44       659\n",
    "           2       0.37      0.45      0.40       659\n",
    "           3       0.26      0.08      0.12       660\n",
    "           4       0.20      0.05      0.09       660\n",
    "           5       0.38      0.31      0.34       659\n",
    "           6       0.42      0.76      0.55       660\n",
    "\n",
    "    accuracy                           0.38      4616\n",
    "   macro avg       0.35      0.38      0.34      4616\n",
    "weighted avg       0.35      0.38      0.34      4616\n",
    "\n",
    "\n",
    "📊 Evaluando df_v7.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.29      0.29      0.29        24\n",
    "           2       0.63      0.62      0.62       279\n",
    "           3       0.64      0.64      0.64       473\n",
    "           4       0.51      0.55      0.53       195\n",
    "           5       0.46      0.32      0.38        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.60      1011\n",
    "   macro avg       0.36      0.35      0.35      1011\n",
    "weighted avg       0.60      0.60      0.59      1011\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.00      0.00      0.00        24\n",
    "           2       0.58      0.62      0.60       279\n",
    "           3       0.61      0.71      0.65       473\n",
    "           4       0.51      0.37      0.43       195\n",
    "           5       0.33      0.14      0.19        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.58      1011\n",
    "   macro avg       0.29      0.26      0.27      1011\n",
    "weighted avg       0.55      0.58      0.56      1011\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.00      0.00      0.00        24\n",
    "           2       0.64      0.60      0.62       279\n",
    "           3       0.56      0.82      0.67       473\n",
    "           4       0.63      0.21      0.32       195\n",
    "           5       0.00      0.00      0.00        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.59      1011\n",
    "   macro avg       0.26      0.23      0.23      1011\n",
    "weighted avg       0.56      0.59      0.54      1011\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.00      0.00      0.00         2\n",
    "           1       0.00      0.00      0.00        24\n",
    "           2       0.79      0.15      0.25       279\n",
    "           3       0.48      0.97      0.65       473\n",
    "           4       0.25      0.01      0.01       195\n",
    "           5       0.00      0.00      0.00        37\n",
    "           6       0.00      0.00      0.00         1\n",
    "\n",
    "    accuracy                           0.50      1011\n",
    "   macro avg       0.22      0.16      0.13      1011\n",
    "weighted avg       0.49      0.50      0.37      1011\n",
    "\n",
    "\n",
    "📊 Evaluando df_v8.csv\n",
    "\n",
    "🌳 Árbol de Decisión:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00       473\n",
    "           1       0.96      1.00      0.98       473\n",
    "           2       0.90      0.90      0.90       473\n",
    "           3       0.88      0.78      0.83       473\n",
    "           4       0.89      0.93      0.91       473\n",
    "           5       0.98      1.00      0.99       473\n",
    "           6       1.00      1.00      1.00       474\n",
    "\n",
    "    accuracy                           0.94      3312\n",
    "   macro avg       0.94      0.94      0.94      3312\n",
    "weighted avg       0.94      0.94      0.94      3312\n",
    "\n",
    "\n",
    "👥 KNN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      1.00       473\n",
    "           1       0.86      1.00      0.93       473\n",
    "           2       0.76      0.74      0.75       473\n",
    "           3       0.68      0.54      0.60       473\n",
    "           4       0.78      0.73      0.75       473\n",
    "           5       0.89      1.00      0.94       473\n",
    "           6       1.00      1.00      1.00       474\n",
    "\n",
    "    accuracy                           0.86      3312\n",
    "   macro avg       0.85      0.86      0.85      3312\n",
    "weighted avg       0.85      0.86      0.85      3312\n",
    "\n",
    "\n",
    "💠 SVM:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      1.00      0.99       473\n",
    "           1       0.83      0.97      0.89       473\n",
    "           2       0.74      0.64      0.69       473\n",
    "           3       0.60      0.46      0.52       473\n",
    "           4       0.64      0.68      0.66       473\n",
    "           5       0.79      0.89      0.83       473\n",
    "           6       1.00      1.00      1.00       474\n",
    "\n",
    "    accuracy                           0.81      3312\n",
    "   macro avg       0.80      0.81      0.80      3312\n",
    "weighted avg       0.80      0.81      0.80      3312\n",
    "\n",
    "\n",
    "🧠 Red Neuronal (PyTorch):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.53      0.58      0.55       473\n",
    "           1       0.39      0.64      0.48       473\n",
    "           2       0.41      0.27      0.32       473\n",
    "           3       0.25      0.14      0.18       473\n",
    "           4       0.22      0.02      0.04       473\n",
    "           5       0.35      0.32      0.33       473\n",
    "           6       0.50      1.00      0.67       474\n",
    "\n",
    "    accuracy                           0.42      3312\n",
    "   macro avg       0.38      0.42      0.37      3312\n",
    "weighted avg       0.38      0.42      0.37      3312]\"\"\"\n",
    "\n",
    "# Patrones para identificar bloques de evaluación\n",
    "eval_blocks = re.split(r\"\\n\\n(?=\\ud83d\\udcca Evaluando df_v\\d\\.csv)\", texto_resultados)\n",
    "\n",
    "# Lista para guardar los resultados\n",
    "resultados = []\n",
    "\n",
    "for bloque in eval_blocks:\n",
    "    match_version = re.search(r\"Evaluando (df_v\\d\\.csv)\", bloque)\n",
    "    version = match_version.group(1) if match_version else \"\"\n",
    "\n",
    "    for modelo in [\"\\U0001f333.*?\\n\", \"\\U0001f46e.*?\\n\", \"\\ud83d\\udd20.*?\\n\", \"\\U0001f9e0.*?\\n\"]:\n",
    "        modelo_match = re.search(modelo, bloque)\n",
    "        if not modelo_match:\n",
    "            continue\n",
    "\n",
    "        nombre_modelo = modelo_match.group().strip().split(' ')[-1]\n",
    "\n",
    "        # Extraer métricas globales (accuracy, macro avg, weighted avg)\n",
    "        metrics = {\n",
    "            'accuracy': None,\n",
    "            'precision': None,\n",
    "            'recall': None,\n",
    "            'f1-score': None\n",
    "        }\n",
    "\n",
    "        acc_match = re.search(r\"accuracy\\s+(\\d\\.\\d+)\", bloque)\n",
    "        if acc_match:\n",
    "            metrics['accuracy'] = float(acc_match.group(1))\n",
    "\n",
    "        macro_match = re.search(r\"macro avg\\s+(\\d\\.\\d+)\\s+(\\d\\.\\d+)\\s+(\\d\\.\\d+)\", bloque)\n",
    "        if macro_match:\n",
    "            metrics['precision'] = float(macro_match.group(1))\n",
    "            metrics['recall'] = float(macro_match.group(2))\n",
    "            metrics['f1-score'] = float(macro_match.group(3))\n",
    "\n",
    "        resultados.append({\n",
    "            'dataset': version,\n",
    "            'modelo': nombre_modelo,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "# Crear DataFrame\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"metricas_completas.csv\", index=False)\n",
    "print(df_resultados)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
